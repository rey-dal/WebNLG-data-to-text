{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca9f16bcb26e4e7ea5d6db6968951f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0913d2b3944e4c21b555e0b8d09d2266",
              "IPY_MODEL_1ca3a538a4a2421d8d839ed06b555354",
              "IPY_MODEL_4ab2a8c62d5941a8b01662c936e9187e"
            ],
            "layout": "IPY_MODEL_f88851fa2eb5451e9d31435799dee80a"
          }
        },
        "0913d2b3944e4c21b555e0b8d09d2266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6752813c110649ebb034a9703ae5bfc1",
            "placeholder": "​",
            "style": "IPY_MODEL_592e94152ff644999257054e5a55028e",
            "value": "spiece.model: 100%"
          }
        },
        "1ca3a538a4a2421d8d839ed06b555354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad3d4ff84194a27aa63941210d251d8",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_361409b9875b48aaa6e6c15719af29cf",
            "value": 791656
          }
        },
        "4ab2a8c62d5941a8b01662c936e9187e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daac68e7306345979fac36a141e7e057",
            "placeholder": "​",
            "style": "IPY_MODEL_b446f943007c424baf25ab12a2c7c3b0",
            "value": " 792k/792k [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "f88851fa2eb5451e9d31435799dee80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6752813c110649ebb034a9703ae5bfc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592e94152ff644999257054e5a55028e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad3d4ff84194a27aa63941210d251d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361409b9875b48aaa6e6c15719af29cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daac68e7306345979fac36a141e7e057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b446f943007c424baf25ab12a2c7c3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea032090111d4a61b7b9d3814947d61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74eda256bd584207bc8890f0ad2da957",
              "IPY_MODEL_e07d7201fea1400ea526ad8fa88a1764",
              "IPY_MODEL_87c8bdc3b62a47f0ad32be815af71e7c"
            ],
            "layout": "IPY_MODEL_c2af9c26a5484a36a8cf67e5849b4efe"
          }
        },
        "74eda256bd584207bc8890f0ad2da957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79457d6ce4d049f0a2bdc6277350f43e",
            "placeholder": "​",
            "style": "IPY_MODEL_022fa20941bf4bbb8480574fbad6bd0f",
            "value": "tokenizer.json: 100%"
          }
        },
        "e07d7201fea1400ea526ad8fa88a1764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfeb3be2c7ef47edaaa4959cd929fe93",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db8cdae034fd4febba484e682640817e",
            "value": 1389353
          }
        },
        "87c8bdc3b62a47f0ad32be815af71e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9711c8559de4458b23b8f427274cc99",
            "placeholder": "​",
            "style": "IPY_MODEL_122cc22271464f6fac2c5833755db09f",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 4.29MB/s]"
          }
        },
        "c2af9c26a5484a36a8cf67e5849b4efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79457d6ce4d049f0a2bdc6277350f43e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022fa20941bf4bbb8480574fbad6bd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfeb3be2c7ef47edaaa4959cd929fe93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8cdae034fd4febba484e682640817e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9711c8559de4458b23b8f427274cc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122cc22271464f6fac2c5833755db09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2527e3a1738c411da26a1bedc004dcf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4490cdaf500c4e5ca37f8381dc2daa7f",
              "IPY_MODEL_a7eda9e61ca04e55b1dbfc127a29c4fb",
              "IPY_MODEL_6f0b8f4607774de5b95554b98b492a62"
            ],
            "layout": "IPY_MODEL_b87cd032e392420f82e5c86260f4530c"
          }
        },
        "4490cdaf500c4e5ca37f8381dc2daa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eb2766734f3497083117b548ea7a3b0",
            "placeholder": "​",
            "style": "IPY_MODEL_56b6fc50d61f46c89be8abb8458928a2",
            "value": "config.json: 100%"
          }
        },
        "a7eda9e61ca04e55b1dbfc127a29c4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16bf42819af34c5c93d99db23820e110",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73b4f017baa444419e84f8758f0b23d2",
            "value": 1208
          }
        },
        "6f0b8f4607774de5b95554b98b492a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a240205e104135affaa3519374539f",
            "placeholder": "​",
            "style": "IPY_MODEL_a8c5b21d60d546dab78cba78f79b5ccb",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 83.5kB/s]"
          }
        },
        "b87cd032e392420f82e5c86260f4530c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb2766734f3497083117b548ea7a3b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b6fc50d61f46c89be8abb8458928a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16bf42819af34c5c93d99db23820e110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b4f017baa444419e84f8758f0b23d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3a240205e104135affaa3519374539f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c5b21d60d546dab78cba78f79b5ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "509148f79e174d558b405e83f12eedac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab60c6ade46446aaab3887308eba6293",
              "IPY_MODEL_d44a38c393554425ad975349a22fbb7b",
              "IPY_MODEL_6a8e20a9c5dc4cc0b8f35584a8195ca7"
            ],
            "layout": "IPY_MODEL_b499fd09e6f949b5b5b7ee17746c69a6"
          }
        },
        "ab60c6ade46446aaab3887308eba6293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b86a3bf5070f46359ec626ebf3eef3b6",
            "placeholder": "​",
            "style": "IPY_MODEL_298dd403114346b68b7a159bf67853a9",
            "value": "model.safetensors: 100%"
          }
        },
        "d44a38c393554425ad975349a22fbb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7155e19ab7de4cbd93d0c2a478e8c17b",
            "max": 891646390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2900eef74f094b1d8df007148250ee59",
            "value": 891646390
          }
        },
        "6a8e20a9c5dc4cc0b8f35584a8195ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375c27ad99ab441ba752c428635080c9",
            "placeholder": "​",
            "style": "IPY_MODEL_835741277bfb41b0a27cdd8f12fc219a",
            "value": " 892M/892M [00:07&lt;00:00, 174MB/s]"
          }
        },
        "b499fd09e6f949b5b5b7ee17746c69a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86a3bf5070f46359ec626ebf3eef3b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298dd403114346b68b7a159bf67853a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7155e19ab7de4cbd93d0c2a478e8c17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2900eef74f094b1d8df007148250ee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "375c27ad99ab441ba752c428635080c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835741277bfb41b0a27cdd8f12fc219a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e387fbec26142e087093ade75afcfe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_728fca7794fd44aea9a4acbe19b3425c",
              "IPY_MODEL_4dce94ae6c2344c78c6a0db48327570d",
              "IPY_MODEL_99550fec38db47e5a07ef4fe36a0117e"
            ],
            "layout": "IPY_MODEL_932bc551fb6f40f2a27859e50060112b"
          }
        },
        "728fca7794fd44aea9a4acbe19b3425c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401bdf8e552844e180303259bd4501b9",
            "placeholder": "​",
            "style": "IPY_MODEL_cbf1869bcf1e4bbd963745901247da40",
            "value": "generation_config.json: 100%"
          }
        },
        "4dce94ae6c2344c78c6a0db48327570d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9faca53a371b438cb452a91445173725",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b61c357a050048329d057d08df7b735d",
            "value": 147
          }
        },
        "99550fec38db47e5a07ef4fe36a0117e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d7f350acd44bd18728fabfd82d76e4",
            "placeholder": "​",
            "style": "IPY_MODEL_62e4e9db5a2e4c4d89d8930c7cc85868",
            "value": " 147/147 [00:00&lt;00:00, 4.54kB/s]"
          }
        },
        "932bc551fb6f40f2a27859e50060112b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401bdf8e552844e180303259bd4501b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf1869bcf1e4bbd963745901247da40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9faca53a371b438cb452a91445173725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b61c357a050048329d057d08df7b735d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64d7f350acd44bd18728fabfd82d76e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e4e9db5a2e4c4d89d8930c7cc85868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Viuf5RhzKG00"
      },
      "source": [
        "# Génération automatique de textes (data-to-text) par adaptation d'un modèle préappris\n",
        "\n",
        "Suite au dernier TP de `Génération automatique de textes neuronale avec une architecture encodeur/décodeur`, nous poursuivons la tâche de génération automatique de textes à partir de représentations sémantiques. Nous reprennons le même ensemble de données : le corpus [WebNLG](https://webnlg-challenge.loria.fr/challenge_2020/) qui a été mis en place pour un défi de génération à partir de données issues du _web sémantique_.\n",
        "\n",
        "Dans le dernier TP, contrairement à l'aproche encodeur/décodeur précedente qui apprenait le modèle avec une initialisation aléatoire, nous utiliserons un modèle préappris. Ces modèles appartiennent à la catégories des modèles de fondation (_fundation models_) et sont appris sur une grande quantité de données pour obtenir une modèlisation très générique. Ils faut ensuite les adapter (_fine-tunning_) à la tâche visée.   \n",
        "\n",
        "Dans ce TP, nous utiliserons le modèle `T5`.\n",
        "\n",
        "Références :\n",
        "- [Data to Text generation with T5; Building a simple yet advanced NLG model](https://towardsdatascience.com/data-to-text-generation-with-t5-building-a-simple-yet-advanced-nlg-model-b5cce5a6df45)\n",
        "- [T5 sur huggingface](https://huggingface.co/transformers/model_doc/t5.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCX69uzNaYF2"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T42IKo8YhGr"
      },
      "source": [
        "## Pré-apprentissage  Séquence à Séquence\n",
        "En octobre 2019, des équipes de Google et de Facebook ont publié de nouveaux articles sur des modèles pré-appris `transformers` :  [T5](https://arxiv.org/abs/1910.10683) et [BART](https://arxiv.org/abs/1910.13461).\n",
        "\n",
        "Les modèles ont obtenu de meilleures performances sur des tâches de génération, telles que le résumé automatique, grâce à deux modifications :\n",
        "- Considérer un modèle transformeur complet (Encodeur de type BERT et décodeur de type GPT)\n",
        "- Remplacer l'objectif de pré-apprentissage consistant à remplir des blancs (masquage) de BERT par un objectif d'apprentissage plus complexe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKt-Ioar-i7i"
      },
      "source": [
        "### Questions\n",
        "1. Donnez les principales caractéristiques et differences entre les modèles pré-entrainés `BERT`, `GPT-2`, `BART` et `T5` ? Référez-vous au cours et n'hésitez pas à faire des recherches sur internet.\n",
        "2. Quelle a été la méthode d'apprentissage de `T5`?\n",
        "3. Quelle est la stratégie employée pour que `T5` pré-apprennent certaines tâches.  \n",
        "\n",
        "\n",
        "BERT:\n",
        "Architecture : Encodeur uniquement\n",
        "\n",
        "Objectif de pré-entraînement : Modélisation du langage masqué (MLM), prédiction de la phrase suivante (NSP)\n",
        "\n",
        "Focus sur les tâches : Principalement des tâches de compréhension et de classification\n",
        "\n",
        "Méthode d'apprentissage : Entraînement supervisé avec des paires de phrases et des segments de texte masqués\n",
        "Stratégie employée : Les tokens sont masqués aléatoirement pour forcer le modèle à prédire le contexte et la relation entre phrases\n",
        "\n",
        "\n",
        "GPT-2\n",
        "\n",
        "Architecture : Décodeur uniquement\n",
        "\n",
        "Objectif de pré-entraînement : Modélisation du langage autorégressive\n",
        "\n",
        "Focus sur les tâches : Génération et complétion de texte\n",
        "\n",
        "Méthode d'apprentissage : Entraînement non supervisé sur de grands ensembles de données textuelles\n",
        "\n",
        "Stratégie employée : Prédiction séquentielle des mots dans un texte (modèle unidirectionnel)\n",
        "\n",
        "\n",
        "BART\n",
        "\n",
        "Architecture : Encodeur-décodeur\n",
        "\n",
        "Objectif de pré-entraînement : Auto-encodage de débruitage (reconstruction de texte corrompu)\n",
        "\n",
        "Focus sur les tâches : Combine les forces de BERT et GPT-2 pour diverses tâches\n",
        "\n",
        "Méthode d'apprentissage : Entraînement supervisé avec des entrées bruyées et des cibles propres.\n",
        "Stratégie employée : Diverses corruptions (suppression, remplacement, permutation) appliquées aux entrées pour apprendre à les reconstruire\n",
        "\n",
        "\n",
        "T5\n",
        "\n",
        "Architecture : Encodeur-décodeur\n",
        "\n",
        "Objectif de pré-entraînement : Texte à texte (toutes les tâches sont formulées comme du texte à texte)\n",
        "\n",
        "Focus sur les tâches : Approche unifiée des tâches de PNL avec une entrée et une sortie flexibles\n",
        "\n",
        "Méthode d'apprentissage : Entraînement supervisé avec une formulation standardisée des tâches comme des problèmes de conversion d'entrée-sortie textuelles\n",
        "\n",
        "Stratégie employée : Uniformisation des tâches en une seule approche \"texte à texte\" pour simplifier et généraliser l'entraînement\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj9jVmn3cDk8"
      },
      "source": [
        "## Modèle - T5\n",
        "\n",
        "`T5` peut-être utilisé pour diverses tâches de TALN dont la génération de textes. Nous utiliserons la bibliothèque `transformers` pour télécharger le modèle pré-entraîné `T5` et le mettre en oeuvre dans le code.\n",
        "\n",
        "![T5](https://camo.githubusercontent.com/623b4dea0b653f2ad3f36c71ebfe749a677ac0a1/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f343030362f312a44304a31674e51663876727255704b657944387750412e706e67)\n",
        "\n",
        "La bibliothèque [`transformers`](https://huggingface.co/docs/transformers/index) est développée et maintenue par l'équipe `Hugging Face`. C'est une bibliothèque open-source très utilisées avec Pytorch et Tensorflow.\n",
        "\n",
        "Vous pouvez utiliser différents types de modèles pré-entraînés `T5` ayant des poids et une architecture différents. Les versions disponibles du modèle `T5` dans la bibliothèque `transformer` sont `t5-base`, `t5-large`, `t5-small`, `t5-3B` et `t5-11B`.\n",
        "\n",
        "Pour en savoir plus sur le modèle T5, vous pouvez vous référer à l'article : [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Démo T5\n",
        "\n",
        "Testez la capacité du modèle T5 avec la démo ici : https://huggingface.co/spaces/docs-demos/t5-base\n"
      ],
      "metadata": {
        "id": "TYpPGNZxOLMr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Wh3A2BcLmY"
      },
      "source": [
        "# Corpus\n",
        "Le [Challenge WebNLG](https://webnlg-challenge.loria.fr/challenge_2017/) consiste à générer des descriptions de triplets RDF. Les données d'entraînement consistent en des paires données/texte où les données sont un ensemble de triplets extraits de DBpedia et le texte est une verbalisation de ces triplets.\n",
        "\n",
        "Par exemple, étant donné les trois triplets de DBpedia [a], l'objectif est de générer le texte [b] :\n",
        "\n",
        "> [a]. (Abilene,_Texas | isPartOf | Jones_County,_Texas) (Abilene,_Texas | country | United_States) (United_States | language | English_language)\n",
        "\n",
        "> [b]. Abilene is part of Jones County, Texas in the United States and English is the language of the United States.\n",
        "\n",
        "Le processus de génération est illustré par la figure suivante :\n",
        "\n",
        "<ul>\n",
        "<div class=\"admonition example\">\n",
        "<p><strong>(a) Set of RDF triples</strong>\n",
        "</p><div class=\"highlight\"><pre id=\"__code_1\"><span></span><code><span class=\"nt\">&lt;entry</span> <span class=\"na\">category=</span><span class=\"s\">\"City\"</span> <span class=\"na\">eid=</span><span class=\"s\">\"Id21\"</span> <span class=\"na\">shape=</span><span class=\"s\">\"(X (X) (X) (X) (X))\"</span> <span class=\"na\">shape_type=</span><span class=\"s\">\"sibling\"</span> <span class=\"na\">size=</span><span class=\"s\">\"3\"</span><span class=\"nt\">&gt;</span>\n",
        "    <span class=\"nt\">&lt;modifiedtripleset&gt;</span>\n",
        "        <span class=\"nt\">&lt;mtriple&gt;</span>Abilene,_Texas | isPartOf | Jones_County,_Texas<span class=\"nt\">&lt;/mtriple&gt;</span>\n",
        "        <span class=\"nt\">&lt;mtriple&gt;</span>Jones_County,_Texas | country | United_States<span class=\"nt\">&lt;/mtriple&gt;</span>\n",
        "        <span class=\"nt\">&lt;mtriple&gt;</span>United_States | language | English_language<span class=\"nt\">&lt;/mtriple&gt;</span>        \n",
        "    <span class=\"nt\">&lt;/modifiedtripleset&gt;</span>\n",
        "<span class=\"nt\">&lt;/entry&gt;</span>\n",
        "</code></pre></div><p></p>\n",
        "<p><strong>(b) English text</strong></p>\n",
        "<p><em>Abilene is in Jones County, Texas, U.S. The language spoken in the U.S. is English.</em></p>\n",
        "<p><em>The United States uses the English language and is the location of Abilene, part of Jones County, Texas.</em></p>\n",
        "<p><em>Abilene is part of Jones County, Texas and is located in the United States where the English language is spoken.</em></p>\n",
        "</div>\n",
        "</ul>\n",
        "\n",
        "Les differentes version de WebNLG sont accessible à partir de ce [dépot](https://gitlab.com/shimorina/webnlg-dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQdo1tK6pdi3"
      },
      "source": [
        "## Questions\n",
        "1. Observez les différents répertoires `dev/test/train` dans `release_v3.0/en`, quelles sont les caractéristiques des données présentes ?\n",
        "\n",
        "(Par exemple, différents triples, diverses catégories, `originaltripleset` vs. `modifiedtripleset` et les phrases de référence.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOKQII18oEAM"
      },
      "source": [
        "> Le jeu de données `WebNLG Challenge` se compose de 21 855 paires données/texte avec un total de 8 372 données distinctes en entrée. Les données d'entrée décrivent des entités appartenant à neuf catégories DBpedia distinctes, à savoir : _astronaute_, _université_, _monument_, _bâtiment_, _personnage de bande dessinée_, _nourriture_, _aéroport_, _équipe sportive_ et _littérature_. Une nouvelle version du jeu de données a été diffusée comprenant 15 catégories DBpedia. Les nouvelles catégories comprennent _corps céleste_, _transport_, _ville_, _athlète_, _personnage politique_, _artiste_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYp-x3b6oT-F"
      },
      "source": [
        "# Prétraitement du corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les lignes de code suivantes sont facultatives, vous pouvez les utiliser si vous souhaitez sauvegarder les modèles entraînés dans votre Google Drive.\n",
        "\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "\n",
        "Il y a différentes façons pour sauvegarder le modèle, vous pourrez en apprendre plus en suivant les liens ci-dessous :\n",
        "\n",
        "- [SAVING AND LOADING MODELS](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
        "\n",
        "- [Best way to save a trained model in PyTorch?](https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch)\n",
        "\n",
        "- [How to save our model to Google Drive and reuse it](https://medium.com/@ml_kid/how-to-save-our-model-to-google-drive-and-reuse-it-2c1028058cb2)"
      ],
      "metadata": {
        "id": "rZLGexl16rEV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf1uUqSEKKgk"
      },
      "source": [
        "## Installation des paquets nécessaires\n",
        "\n",
        "Nous allons devoir utiliser un certain nombre de bilbiothèques. Executez le code ci-dessous pour les installer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ki1-m-5UUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300725f3-b8f0-4409-941b-ddbd9c77206c"
      },
      "source": [
        "# !pip install transformers\n",
        "!pip install transformers[torch]\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.5.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (3.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalKR6o4KP22"
      },
      "source": [
        "Par ailleurs, pour tous le reste du TP nous aurons besoin des imports python suivants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB6rH4GenWpN"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import  Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "from transformers.optimization import Adafactor\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérification de la disponibilité du GPU\n",
        "if torch.cuda.is_available():\n",
        "    dev = torch.device(\"cuda:0\")\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    dev = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "metadata": {
        "id": "_XLLwtL3uEzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d7c64f-82d8-4fe7-abed-ca557578b8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aWMq3DOKl34"
      },
      "source": [
        "## Téléchargement des données et partitionnement\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the official data of webnlg2020 version 3.0\n",
        "url = 'https://gitlab.com/shimorina/webnlg-dataset/-/archive/master/webnlg-dataset-master.zip?path=release_v3.0/en/'\n",
        "urllib.request.urlretrieve(url, 'web.zip')\n",
        "with zipfile.ZipFile('web.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('web')"
      ],
      "metadata": {
        "id": "-CiYg63ipRhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE IMPORTANT** :\n",
        "\n",
        "Pour réduire le temps d'entraînement, nous n'utiliserons que les données de la catégorie **`City`** du répertoire des différents nombres de triples (p.ex. **`3triples`**) au lieu du corpus entier. Vous pourrez considérer plus d'exemples d'apprentissage pendant ce TP."
      ],
      "metadata": {
        "id": "rIX8z_CNo0pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "function to preprocess the data\n",
        "get \"input_text\" and \"target_text\"\n",
        "\"prefix\" for train and dev\n",
        "keep the normal triplets as it is and join multiple triplets with “&&”\n",
        "\"\"\"\n",
        "\n",
        "def process_data(prefix):\n",
        "  # Due to limit of computing resources,\n",
        "  # we start with only the \"City\" category of various triples files for our training and validation\n",
        "  # then you can try \"/3triples/*.xml\" for all 3triples\n",
        "  # and \"/**/*.xml\" for all the data\n",
        "  # following are some statistics:\n",
        "  # TRAIN: all (1-7triples): 35190; 3triples: 7610; 3triples/City.xml: 679\n",
        "  # DEV: all: 4462; 3triples: 952; City.xml: 86\n",
        "  files = glob.glob(\"/content/web/webnlg-dataset-master-release_v3.0-en-/release_v3.0/en/\" + \\\n",
        "                    prefix + \"/?triples/City.xml\", recursive=True) # used to use /3triples/City.xml,\n",
        "\n",
        "  triple_re=re.compile('(\\d)triples')\n",
        "  data_dct={}\n",
        "  for file in files:\n",
        "      tree = ET.parse(file)\n",
        "      root = tree.getroot()\n",
        "      triples_num=int(triple_re.findall(file)[0])\n",
        "      for sub_root in root:\n",
        "          for ss_root in sub_root:\n",
        "              strutured_master=[]\n",
        "              unstructured=[]\n",
        "              for entry in ss_root:\n",
        "                  unstructured.append(entry.text)\n",
        "                  strutured=[triple.text for triple in entry]\n",
        "                  strutured_master.extend(strutured)\n",
        "              unstructured=[i for i in unstructured if i.replace('\\n','').strip()!='' ]\n",
        "              strutured_master=strutured_master[-triples_num:]\n",
        "              # keep the normal triplets as it is and join multiple triplets with “&&”\n",
        "              strutured_master_str=(' && ').join(strutured_master)\n",
        "              data_dct[strutured_master_str]=unstructured\n",
        "\n",
        "  mdata_dct={\"challenge\":[], \"input_text\":[], \"target_text\":[]}\n",
        "  for st,unst in data_dct.items():\n",
        "      for i in unst:\n",
        "          mdata_dct['challenge'].append('webNLG')\n",
        "          mdata_dct['input_text'].append(st)\n",
        "          mdata_dct['target_text'].append(i)\n",
        "  df=pd.DataFrame(mdata_dct)\n",
        "  df.to_csv('data/webNLG2020.' + prefix + '.csv')"
      ],
      "metadata": {
        "id": "P7CRHHZ1pTsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72KuypV378nb"
      },
      "source": [
        "# create the data directory and load the data partitions\n",
        "!mkdir -p data\n",
        "\n",
        "for u in ['train', 'dev']:\n",
        "    process_data(u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('data/webNLG2020.train.csv', index_col=[0])\n",
        "dev_df=pd.read_csv('data/webNLG2020.dev.csv', index_col=[0])\n",
        "\n",
        "print(\"nombre d'exemples des partitions train et dev:\")\n",
        "print(len(train_df))\n",
        "print(len(dev_df))"
      ],
      "metadata": {
        "id": "aEDl4W-cpH8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a25a77-d8cf-4838-8cb6-c42160cc8860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nombre d'exemples des partitions train et dev:\n",
            "2415\n",
            "295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(5)\n",
        "dev_df.head(5)"
      ],
      "metadata": {
        "id": "Hg7x5uKlq8AU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a662f71a-3d42-441e-b4c5-ebfb9812e8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  challenge                                         input_text  \\\n",
              "0    webNLG  Albany,_Georgia | isPartOf | United_States && ...   \n",
              "1    webNLG  Albany,_Georgia | isPartOf | United_States && ...   \n",
              "2    webNLG  Albany,_Georgia | isPartOf | United_States && ...   \n",
              "3    webNLG  Albany,_Oregon | isPartOf | Oregon && Oregon |...   \n",
              "4    webNLG  Albany,_Oregon | isPartOf | Oregon && Oregon |...   \n",
              "\n",
              "                                         target_text  \n",
              "0  Albany, Georgia is in the United States, home ...  \n",
              "1  Albany, Georgia is part of the United States o...  \n",
              "2  Albany, Georgia, is in the United States where...  \n",
              "3  Portland is the largest city in Oregon which a...  \n",
              "4  Portland is the largest city in Oregon, the st...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06779647-d73c-47a8-acbf-199ae96ce587\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>challenge</th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>webNLG</td>\n",
              "      <td>Albany,_Georgia | isPartOf | United_States &amp;&amp; ...</td>\n",
              "      <td>Albany, Georgia is in the United States, home ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>webNLG</td>\n",
              "      <td>Albany,_Georgia | isPartOf | United_States &amp;&amp; ...</td>\n",
              "      <td>Albany, Georgia is part of the United States o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>webNLG</td>\n",
              "      <td>Albany,_Georgia | isPartOf | United_States &amp;&amp; ...</td>\n",
              "      <td>Albany, Georgia, is in the United States where...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>webNLG</td>\n",
              "      <td>Albany,_Oregon | isPartOf | Oregon &amp;&amp; Oregon |...</td>\n",
              "      <td>Portland is the largest city in Oregon which a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>webNLG</td>\n",
              "      <td>Albany,_Oregon | isPartOf | Oregon &amp;&amp; Oregon |...</td>\n",
              "      <td>Portland is the largest city in Oregon, the st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06779647-d73c-47a8-acbf-199ae96ce587')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06779647-d73c-47a8-acbf-199ae96ce587 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06779647-d73c-47a8-acbf-199ae96ce587');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b2cf317-09e2-4883-9690-297fd3053caf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b2cf317-09e2-4883-9690-297fd3053caf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b2cf317-09e2-4883-9690-297fd3053caf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dev_df",
              "summary": "{\n  \"name\": \"dev_df\",\n  \"rows\": 295,\n  \"fields\": [\n    {\n      \"column\": \"challenge\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"webNLG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 108,\n        \"samples\": [\n          \"United_States | language | English_language && United_States_House_of_Representatives | location | United_States && United_States_House_of_Representatives | isPartOf | United_States_Congress && Anaheim,_California | leaderTitle | United_States_House_of_Representatives\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"Abilene, part of Taylor County, Texas, in the United States, where the capital is Washington, D.C.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ5doj3KEcbC"
      },
      "source": [
        "### Questions\n",
        "1. Donnez le nombre d'exemples utilisés pour l'apprentissage du modèle et pour sa validation (partition dev).\n",
        "\n",
        "nombre d'exemples des partitions train et dev:\n",
        "2415,\n",
        "295\n",
        "\n",
        "2. Quel est le rôle du terme `webNLG` dans les données ?  \n",
        "\n",
        "webNLG sert à identifier l'ensemble de données et à fournir un contexte au modèle T5 pendant l'entraînement\n",
        "\n",
        "2. Quand vous aurez suffisemment avancé dans le TP, vous pourrez augmenter le corpus d'apprentissage. En anticipation de ce moment, regardez le code ci-dessous et essayez de comprendre comment vous pourriez l'utiliser pour progresser pas à pas (notamment pour le debuggage).\n",
        "\n",
        "Ce code permet de réduire la taille des données d'apprentissage et de validation pour un débogage plus rapide et une augmentation progressive du corpus. En ajustant le nombre d'exemples utilisés, on peut observer l'évolution des performances du modèle et identifier les problèmes potentiels.\n",
        "```\n",
        "# Put a small number for fast debug\n",
        "train_df=train_df.iloc[:100,:] # change the number of your training data here\n",
        "print(train_df)\n",
        "\n",
        "dev_df=dev_df.iloc[:30,:]\n",
        "print(dev_df)\n",
        "\n",
        "```\n",
        "\n",
        "3. Que font les lignes de code ci-dessous ?\n",
        "\n",
        "```\n",
        "train_df=train_df.sample(frac = 1)\n",
        "dev_df=dev_df.sample(frac = 1)\n",
        "```\n",
        "\n",
        "Ces lignes mélangent aléatoirement les lignes des DataFrames train_df et dev_df. Cela permet d'éviter les biais liés à l'ordre des données et favorise une meilleure généralisation du modèle. Le paramètre frac=1 spécifie que toutes les lignes doivent être incluses, mais dans un ordre aléatoire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgsIcgFgRCwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c744fd-c28f-482b-ab56-b774576ff3bc"
      },
      "source": [
        "#Pandas sample() is used to generate a sample random row or column from the function caller data frame.\n",
        "train_df=train_df.sample(frac = 1) # frac: Float value, Returns (float value * length of data frame values ). frac cannot be used with n.\n",
        "print(train_df)\n",
        "\n",
        "print(\"---------------\")\n",
        "\n",
        "dev_df=dev_df.sample(frac = 1)\n",
        "print(dev_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     challenge                                         input_text  \\\n",
            "492     webNLG  United_States_House_of_Representatives | isPar...   \n",
            "2013    webNLG  Ann_Arbor,_Michigan | isPartOf | Washtenaw_Cou...   \n",
            "1234    webNLG  Amarillo,_Texas | isPartOf | Potter_County,_Te...   \n",
            "1697    webNLG  United_States | ethnicGroup | Native_Americans...   \n",
            "1252    webNLG  Amarillo,_Texas | isPartOf | Potter_County,_Te...   \n",
            "...        ...                                                ...   \n",
            "1567    webNLG  Tarrant_County,_Texas | largestCity | Fort_Wor...   \n",
            "655     webNLG  Anaheim,_California | leader | Tom_Tait && Cal...   \n",
            "598     webNLG  Amarillo,_Texas | isPartOf | Potter_County,_Te...   \n",
            "326     webNLG  Auburn,_Washington | isPartOf | Washington_(st...   \n",
            "35      webNLG  Alabama | country | United_States && Auburn,_A...   \n",
            "\n",
            "                                            target_text  \n",
            "492   The House of Representatives, forms part of th...  \n",
            "2013  Ann Arbor is part of Washtenaw County in Michi...  \n",
            "1234  Amarillo is part of Potter County and Randall ...  \n",
            "1697  In the U.S. we can find Native Americans and a...  \n",
            "1252  Amarillo is part of Potter County in the state...  \n",
            "...                                                 ...  \n",
            "1567  Arlington is located in Tarrant County, Texas ...  \n",
            "655   Anaheim is part of California, where Tom Tait ...  \n",
            "598   Amarillo, is in Potter County, Texas (Capital:...  \n",
            "326   Auburn is located within the state of Washingt...  \n",
            "35    Auburn is located in Alabama, in the United St...  \n",
            "\n",
            "[2415 rows x 3 columns]\n",
            "---------------\n",
            "    challenge                                         input_text  \\\n",
            "234    webNLG  Amarillo,_Texas | isPartOf | Potter_County,_Te...   \n",
            "99     webNLG  Tarrant_County,_Texas | countySeat | Fort_Wort...   \n",
            "126    webNLG  United_States | language | English_language &&...   \n",
            "6      webNLG  Alexandria,_Indiana | areaTotal | 6.81 (square...   \n",
            "211    webNLG  Abilene,_Texas | elevationAboveTheSeaLevel | 5...   \n",
            "..        ...                                                ...   \n",
            "293    webNLG  United_States_House_of_Representatives | locat...   \n",
            "40     webNLG  Austin,_Texas | country | United_States && Aus...   \n",
            "104    webNLG  Texas | capital | Austin,_Texas && Arlington,_...   \n",
            "225    webNLG  Albuquerque_City_Council | leader | Richard_J....   \n",
            "261    webNLG  Austin,_Texas | country | United_States && Uni...   \n",
            "\n",
            "                                           target_text  \n",
            "234  Amarillo is part of Potter County, Texas which...  \n",
            "99   English is a language spoken in Texas and Hous...  \n",
            "126  Angola is in Indiana which is in the US where ...  \n",
            "6    Alexandria, Indiana (total area 6.81 sq km), h...  \n",
            "211  At 524 metres above sea level, Abilene (Texas)...  \n",
            "..                                                 ...  \n",
            "293  Anaheim in California is led by the United Sta...  \n",
            "40   Austin is part of Travis County, which is in T...  \n",
            "104  Arlington is part of Tarrant County, Texas, th...  \n",
            "225  Albuquerque in New Mexico, United States, is l...  \n",
            "261  Austin, Texas is located in the United States,...  \n",
            "\n",
            "[295 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modèle de génération et apprentissage"
      ],
      "metadata": {
        "id": "FwT12JbtkV_L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JaUpURdLAla"
      },
      "source": [
        "## Chargement du modèle pré-entraîné et du tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H78g1gWLcyFz"
      },
      "source": [
        "Avant de pouvoir alimenter notre modèle avec ces textes, nous devons les prétraiter. Ceci est fait par un  `Tokenizer` de la bibliothèque 🤗 Transformers qui va convertir le texte d'entrée en sequence de tokens (y compris convertir les tokens en leurs IDs correspondants dans le vocabulaire prétraîné) et les mettre dans un format attendu par le modèle, ainsi que générer les autres entrées dont le modèle a besoin.\n",
        "\n",
        "Pour faire tout cela, nous instancions notre tokenizer avec la méthode `AutoTokenizer.from_pretrained`, qui assurera que :\n",
        "\n",
        "- nous obtenons un tokenizer qui correspond à l'architecture du modèle que nous voulons utiliser,\n",
        "- nous téléchargeons le vocabulaire utilisé lors du pré-entraînement de ce point de contrôle (`checkpoint`) spécifique.\n",
        "\n",
        "Ce vocabulaire sera mis en cache, afin qu'il ne soit pas téléchargé à nouveau lors de la prochaine exécution de la cellule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbdZzE0rufVL"
      },
      "source": [
        "Nous utiliserons `t5-base` dans ce TP, vous pouvez regarder la description du modèle [ici](https://huggingface.co/t5-base)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUtimiV0QN92"
      },
      "source": [
        "### Questions\n",
        "\n",
        "1. Quel type de tokenization est mise en oeuvre dans les modèles de language pré-appris ?\n",
        "\n",
        "2. Quel est le type de tokenizer utilisé pour `T5` ? Quel est la difference avec les tokenizers que vous avez vus ?\n",
        "\n",
        "Faites références aux liens suivants :\n",
        "- [Byte-Pair Encoding tokenization](https://huggingface.co/course/chapter6/5?fw=pt)\n",
        "- [WordPiece tokenization](https://huggingface.co/course/chapter6/6?fw=pt)\n",
        "- [huggingface/tokenizers](https://github.com/huggingface/tokenizers)\n",
        "- https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
        "- [transformers.T5Tokenizer](https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5Tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVAXjd6wsOM6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ca9f16bcb26e4e7ea5d6db6968951f6e",
            "0913d2b3944e4c21b555e0b8d09d2266",
            "1ca3a538a4a2421d8d839ed06b555354",
            "4ab2a8c62d5941a8b01662c936e9187e",
            "f88851fa2eb5451e9d31435799dee80a",
            "6752813c110649ebb034a9703ae5bfc1",
            "592e94152ff644999257054e5a55028e",
            "bad3d4ff84194a27aa63941210d251d8",
            "361409b9875b48aaa6e6c15719af29cf",
            "daac68e7306345979fac36a141e7e057",
            "b446f943007c424baf25ab12a2c7c3b0",
            "ea032090111d4a61b7b9d3814947d61f",
            "74eda256bd584207bc8890f0ad2da957",
            "e07d7201fea1400ea526ad8fa88a1764",
            "87c8bdc3b62a47f0ad32be815af71e7c",
            "c2af9c26a5484a36a8cf67e5849b4efe",
            "79457d6ce4d049f0a2bdc6277350f43e",
            "022fa20941bf4bbb8480574fbad6bd0f",
            "dfeb3be2c7ef47edaaa4959cd929fe93",
            "db8cdae034fd4febba484e682640817e",
            "b9711c8559de4458b23b8f427274cc99",
            "122cc22271464f6fac2c5833755db09f",
            "2527e3a1738c411da26a1bedc004dcf5",
            "4490cdaf500c4e5ca37f8381dc2daa7f",
            "a7eda9e61ca04e55b1dbfc127a29c4fb",
            "6f0b8f4607774de5b95554b98b492a62",
            "b87cd032e392420f82e5c86260f4530c",
            "9eb2766734f3497083117b548ea7a3b0",
            "56b6fc50d61f46c89be8abb8458928a2",
            "16bf42819af34c5c93d99db23820e110",
            "73b4f017baa444419e84f8758f0b23d2",
            "b3a240205e104135affaa3519374539f",
            "a8c5b21d60d546dab78cba78f79b5ccb",
            "509148f79e174d558b405e83f12eedac",
            "ab60c6ade46446aaab3887308eba6293",
            "d44a38c393554425ad975349a22fbb7b",
            "6a8e20a9c5dc4cc0b8f35584a8195ca7",
            "b499fd09e6f949b5b5b7ee17746c69a6",
            "b86a3bf5070f46359ec626ebf3eef3b6",
            "298dd403114346b68b7a159bf67853a9",
            "7155e19ab7de4cbd93d0c2a478e8c17b",
            "2900eef74f094b1d8df007148250ee59",
            "375c27ad99ab441ba752c428635080c9",
            "835741277bfb41b0a27cdd8f12fc219a",
            "8e387fbec26142e087093ade75afcfe9",
            "728fca7794fd44aea9a4acbe19b3425c",
            "4dce94ae6c2344c78c6a0db48327570d",
            "99550fec38db47e5a07ef4fe36a0117e",
            "932bc551fb6f40f2a27859e50060112b",
            "401bdf8e552844e180303259bd4501b9",
            "cbf1869bcf1e4bbd963745901247da40",
            "9faca53a371b438cb452a91445173725",
            "b61c357a050048329d057d08df7b735d",
            "64d7f350acd44bd18728fabfd82d76e4",
            "62e4e9db5a2e4c4d89d8930c7cc85868"
          ]
        },
        "outputId": "ab4a037f-7785-4578-8df9-c840e298f0f3"
      },
      "source": [
        "model_name = \"t5-base\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)\n",
        "#moving the model to device(GPU/CPU)\n",
        "model.to(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca9f16bcb26e4e7ea5d6db6968951f6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea032090111d4a61b7b9d3814947d61f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2527e3a1738c411da26a1bedc004dcf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "509148f79e174d558b405e83f12eedac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e387fbec26142e087093ade75afcfe9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"WebNLG: \"\n",
        "\n",
        "def preprocess_function(df):\n",
        "  # inputs, targets = [], []\n",
        "  model_inputs = []\n",
        "  for indx,row in df.iterrows():\n",
        "    inputs = prefix + row[\"input_text\"] + '</s>'\n",
        "    targets = row['target_text']+'</s>'\n",
        "    model_inputs.append(tokenizer(inputs, text_target=targets, max_length=400, truncation=True))\n",
        "  return model_inputs\n",
        "\n",
        "# Application du pre-processing à l'ensemble du dataset\n",
        "train_tok = preprocess_function(train_df)\n",
        "dev_tok = preprocess_function(dev_df)"
      ],
      "metadata": {
        "id": "xPN1kHBEKYPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMe1hKshLgJn"
      },
      "source": [
        "## Entraînement du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGXbdIOU1Su5"
      },
      "source": [
        "Les étapes de l'entraînement :\n",
        "\n",
        "- Déplacer les données vers le GPU (facultatif)\n",
        "- Effacer les gradients en utilisant `optimizer.zero_grad()`\n",
        "- Effectuer une passe avant (`forward`)\n",
        "- Calcul de la perte (`loss`)\n",
        "- Effectuer un passage en arrière (`backward`) en utilisant `loss.backward()` pour calculer les gradients\n",
        "- Effectuer un pas de l'optimiseur en utilisant `optimizer.step()` pour mettre à jour les poids.\n",
        "\n",
        "Dans la pratique, la classe Trainer de HuggingFace implémente ces étapes pour nous. Il suffit de spécifier les paramètres à utiliser pendant l'entrainement dans un objet de type Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By changing to False, the trainer will use the existing `model` and continue the training\n",
        "# Setting to `True` reloads a fresh t5-base model\n",
        "\n",
        "train_from_scratch = True\n",
        "\n",
        "if train_from_scratch:\n",
        "  model = T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)\n",
        "  model.to(dev)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name, max_length=400)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"t5-webnlg\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=8,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    load_best_model_at_end=True,\n",
        "    generation_max_length=128,\n",
        "    # predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=dev_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "D0tA-U4VJx_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "DUJO3ahdNnMv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "6a597b74-bdf8-4c7b-b14c-c869669c7155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1208' max='1208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1208/1208 15:12, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.055900</td>\n",
              "      <td>0.742487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.781900</td>\n",
              "      <td>0.679335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.703600</td>\n",
              "      <td>0.659469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.653300</td>\n",
              "      <td>0.651720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.621600</td>\n",
              "      <td>0.648213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.590300</td>\n",
              "      <td>0.643172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.572100</td>\n",
              "      <td>0.644195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.557300</td>\n",
              "      <td>0.647128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1208, training_loss=0.6920110563568721, metrics={'train_runtime': 915.0956, 'train_samples_per_second': 21.113, 'train_steps_per_second': 1.32, 'total_flos': 2981657646489600.0, 'train_loss': 0.6920110563568721, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8C6gqK1XkX"
      },
      "source": [
        "Les étapes de validation et de test sont également similaires, le Trainer de HuggingFace nous calcule le loss sur les données de validation, la variable que l'on a donné pour `eval_dataset` dans les paramètre de la classe Trainer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "dk49nI1QOCgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d1ba8157-6e00-4a5d-b4cd-41268e9921f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [37/37 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6431723833084106, 'eval_runtime': 2.2153, 'eval_samples_per_second': 133.162, 'eval_steps_per_second': 16.702, 'epoch': 8.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the log_history\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# Extract eval_loss and train_loss\n",
        "\n",
        "eval_losses = [entry['eval_loss'] for entry in log_history if 'eval_loss' in entry]\n",
        "eval_epochs = [entry['epoch'] for entry in log_history if 'eval_loss' in entry]\n",
        "\n",
        "train_losses = [entry['loss'] for entry in log_history if 'loss' in entry]\n",
        "train_epochs = [entry['epoch'] for entry in log_history if 'loss' in entry]\n",
        "\n",
        "# Plot the learning curves\n",
        "plt.plot(train_epochs, train_losses, label=\"Train Loss\")\n",
        "plt.plot(eval_epochs, eval_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Curves\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u0fPCMFurqAR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "db4784ae-6e9c-49ad-d7e0-9369fdaf55e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv3VHD585lc9"
      },
      "source": [
        "## Évaluation (inspection) du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRoTTDnxKegy"
      },
      "source": [
        "# La fonction d'inférence\n",
        "def generate(text):\n",
        "  model.eval()\n",
        "  # model.to(dev)\n",
        "  input_ids = tokenizer(\"WebNLG:{} </s>\".format(text), return_tensors=\"pt\")  # Batch size 1\n",
        "  input_ids.to(dev)\n",
        "  s = time.time()\n",
        "  outputs = model.generate(**input_ids)\n",
        "  gen_text=tokenizer.decode(outputs[0]).replace('<pad>','').replace('</s>','')\n",
        "  elapsed = time.time() - s\n",
        "  print('Generated in {} seconds'.format(str(elapsed)[:4]))\n",
        "\n",
        "  return gen_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions\n",
        "1. Quelle est la fonction de `WebNLG` ici pour la génération de texte ?\n",
        "\n",
        "Le WebNLG est essentiel pour que le modèle T5 puisse générer du texte en langage naturel à partir de données WebNLG. Il fournit le contexte, le format des données et les instructions nécessaires pour que le modèle puisse effectuer la tâche correctement.\n",
        "\n",
        "2. Analysez les sorties pour les exemples choisis suivants.\n",
        "\n",
        "Les exemples montrent que T5 génère généralement des textes grammaticaux et informatifs, mais parfois avec des erreurs factuelles ou des omissions. La qualité de la sortie dépend de la complexité et de la clarté des triplets d'entrée.\n",
        "\n",
        "3. Quelle semble être la capacité des modèles à traiter les nombres ?\n",
        "\n",
        "T5 semble capable de traiter les nombres, les intégrant dans les phrases générées. Cependant, il peut parfois mal interpréter leur signification ou leur format, ce qui nécessite une attention particulière lors de l'évaluation des résultats.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QxO16Q2Byiy1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SbF3PB7dvwc"
      },
      "source": [
        "1 triple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o88iAZv6eGeL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "604c691f-7760-43e5-b249-ac75a4455316"
      },
      "source": [
        "generate('MotorSport_Vision | city | Fawkham')\n",
        "# reference: MotorSport Vision is located in the city of Fawkham."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.84 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fawkham is the location of the MotorSport Vision in the city of Fawk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Atlanta | isPartOf | Georgia_(U.S._state)')\n",
        "#Atlanta is part of Georgia , US ."
      ],
      "metadata": {
        "id": "C7WnbhPJGXsZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f0d23bf8-357b-43a2-c2ab-220c54bd7164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.35 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Atlanta is part of the state of Georgia in the United States.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Grenoble | capital | Alpes_(France)')"
      ],
      "metadata": {
        "id": "St3T-vl5GT6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "618506b2-97c1-4c51-cabf-2db213671926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.43 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of France is Alpes. The city of Renoble is located in the French'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTEWaVpgo7AM"
      },
      "source": [
        "2 triples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJiKxpHId0dp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a8834fe0-31fe-4d27-d265-934fb2e02da5"
      },
      "source": [
        "generate('Nie_Haisheng | birthDate | 1964-10-13 && Nie_Haisheng | occupation | Fighter_pilot')\n",
        "# reference: Nie Haisheng, born on October 13, 1964, worked as a fighter pilot.\n",
        "# Nie Haisheng is a former fighter pilot who was born on October 13, 1964.\n",
        "# Nie Haisheng born on 10/13/1964 is a fighter pilot."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.46 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Nie Haisheng was a Fighter pilot and his birthdate was 1964-10-13.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc1EikW3Lqal",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d4a99ce3-b710-4a59-d42c-a935085aa55f"
      },
      "source": [
        "generate('Grenoble | isPartOf | Auvergne-Rhône-Alpes && Grenoble | country | France' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.41 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Grenoble is part of Auvergne-Rhône-Alpes in France.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMTaTa6Wo_Fs"
      },
      "source": [
        "3 triples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Grenoble | isPartOf | Auvergne-Rhône-Alpes && Grenoble | country | France && Auvergne-Rhône-Alpes | language | French_language ')"
      ],
      "metadata": {
        "id": "Gz_IUITwZC-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0bb9d455-e7ca-4dca-e73c-4980368e2526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.46 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Grenoble is part of Auvergne-Rhône-Alpes in France, where French'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbW1yJfwotkO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4ffa6c31-17d8-4066-e556-20c7dce0eb03"
      },
      "source": [
        "generate('Saint_Petersburg | foundingDate | 1703-05-27 && Olga_Bondareva | deathPlace | Saint_Petersburg && Saint_Petersburg | areaTotal | 1439.0')\n",
        "\n",
        "# Saint Petersburg was founded on May 27, 1703 and has a total area of 1439.0, Olga Bondareva passed away at Saint Petersburg.\n",
        "# Saint Petersburg, where Olga Bondareva died, was founded on the 27th of May, 1703 and has a total area of approximately 1439 km2.\n",
        "# Saint Petersburg, where Olga Bondareva died, was founded on May 27, 1703 and consists of a total area of 1439.0 sq/km."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.43 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The total area of Saint Petersburg is 1439.0 square kilometres and the city'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 triples"
      ],
      "metadata": {
        "id": "tFpORwJNGJMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Antioch,_California | utcOffset | \"-7\" && Antioch,_California | populationTotal | 102372 && Antioch,_California | areaCode | 925 && Antioch,_California | areaTotal | 75.324 (square kilometres)')\n",
        "#Antioch , California has a UTC offset of - 7 , the population is 102372 , the area code is 925 , and has a total area of 75.324 square km ."
      ],
      "metadata": {
        "id": "6e9BfamqGKnx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0777e646-e83b-4a00-faa1-17b7b2cf0fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.48 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Antioch, California has a UTC offset of -7, a population of 10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Trane | foundingDate | 1913-01-01 && Trane | location | Ireland && Trane | foundationPlace | La_Crosse,_Wisconsin && Trane | numberOfEmployees | 29000')\n",
        "#Trane, which was founded on January 1st 1913 in La Crosse, Wisconsin, is based in Ireland. It has 29,000 employees."
      ],
      "metadata": {
        "id": "yaW_QXEuGNGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8709c77b-7b29-4f88-faa5-2f72f3ebd1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.44 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Trane, which is located in Ireland, was founded in 1913 and has a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7VarSuEln0j"
      },
      "source": [
        "## Extension du TP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkCp4kmXlu4a"
      },
      "source": [
        "### Questions\n",
        "\n",
        "1. Les données d'apprentissage utilisées dans ce TP sont limitées, à cause du temps et des ressources de calcul. Modifiez le code pour utiliser les données d'autres catégories, observez-vous des changements ?\n",
        "2. Essayez de changer `lr` et `batch_size` et voyez si cela donne de meilleurs résultats."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Airport category"
      ],
      "metadata": {
        "id": "ht6qQ7CQB56D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/web/webnlg-dataset-master-release_v3.0-en-/release_v3.0/en/\" + \\\n",
        "                    prefix + \"/?triples/Airport.xml\", recursive=True)\n",
        "\n",
        "learning_rate = 2e-4\n",
        "batch_size = 8\n"
      ],
      "metadata": {
        "id": "qwuPaarf6KwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "function to preprocess the data\n",
        "get \"input_text\" and \"target_text\"\n",
        "\"prefix\" for train and dev\n",
        "keep the normal triplets as it is and join multiple triplets with “&&”\n",
        "\"\"\"\n",
        "\n",
        "def process_data(prefix):\n",
        "  # Due to limit of computing resources,\n",
        "  # we start with only the \"City\" category of various triples files for our training and validation\n",
        "  # then you can try \"/3triples/*.xml\" for all 3triples\n",
        "  # and \"/**/*.xml\" for all the data\n",
        "  # following are some statistics:\n",
        "  # TRAIN: all (1-7triples): 35190; 3triples: 7610; 3triples/City.xml: 679\n",
        "  # DEV: all: 4462; 3triples: 952; City.xml: 86\n",
        "  files = glob.glob(\"/content/web/webnlg-dataset-master-release_v3.0-en-/release_v3.0/en/\" + \\\n",
        "                    prefix + \"/?triples/Airport.xml\", recursive=True)\n",
        "\n",
        "  triple_re=re.compile('(\\d)triples')\n",
        "  data_dct={}\n",
        "  for file in files:\n",
        "      tree = ET.parse(file)\n",
        "      root = tree.getroot()\n",
        "      triples_num=int(triple_re.findall(file)[0])\n",
        "      for sub_root in root:\n",
        "          for ss_root in sub_root:\n",
        "              strutured_master=[]\n",
        "              unstructured=[]\n",
        "              for entry in ss_root:\n",
        "                  unstructured.append(entry.text)\n",
        "                  strutured=[triple.text for triple in entry]\n",
        "                  strutured_master.extend(strutured)\n",
        "              unstructured=[i for i in unstructured if i.replace('\\n','').strip()!='' ]\n",
        "              strutured_master=strutured_master[-triples_num:]\n",
        "              # keep the normal triplets as it is and join multiple triplets with “&&”\n",
        "              strutured_master_str=(' && ').join(strutured_master)\n",
        "              data_dct[strutured_master_str]=unstructured\n",
        "\n",
        "  mdata_dct={\"challenge\":[], \"input_text\":[], \"target_text\":[]}\n",
        "  for st,unst in data_dct.items():\n",
        "      for i in unst:\n",
        "          mdata_dct['challenge'].append('webNLG')\n",
        "          mdata_dct['input_text'].append(st)\n",
        "          mdata_dct['target_text'].append(i)\n",
        "  df=pd.DataFrame(mdata_dct)\n",
        "  df.to_csv('data/webNLG2020.' + prefix + '.csv')"
      ],
      "metadata": {
        "id": "AVONYj6-Eaol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the data directory and load the data partitions\n",
        "!mkdir -p data\n",
        "\n",
        "for u in ['train', 'dev']:\n",
        "    process_data(u)"
      ],
      "metadata": {
        "id": "IrOGgHIzHsZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('data/webNLG2020.train.csv', index_col=[0])\n",
        "dev_df=pd.read_csv('data/webNLG2020.dev.csv', index_col=[0])\n",
        "\n",
        "print(\"nombre d'exemples des partitions train et dev:\")\n",
        "print(len(train_df))\n",
        "print(len(dev_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdqcELKKHzCd",
        "outputId": "9b8ef487-9cd7-41d8-86f7-6b08cda02aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nombre d'exemples des partitions train et dev:\n",
            "2092\n",
            "253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pandas sample() is used to generate a sample random row or column from the function caller data frame.\n",
        "train_df=train_df.sample(frac = 1) # frac: Float value, Returns (float value * length of data frame values ). frac cannot be used with n.\n",
        "print(train_df)\n",
        "\n",
        "print(\"---------------\")\n",
        "\n",
        "dev_df=dev_df.sample(frac = 1)\n",
        "print(dev_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqBP2JFmH4S3",
        "outputId": "b0641875-a078-4342-b716-b48bbfeb25eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     challenge                                         input_text  \\\n",
            "1280    webNLG  Alpena_County_Regional_Airport | location | Ma...   \n",
            "29      webNLG  Abilene_Regional_Airport | 1stRunwayLengthFeet...   \n",
            "210     webNLG  Allama_Iqbal_International_Airport | location ...   \n",
            "1730    webNLG  Agra_Airport | location | Uttar_Pradesh && Utt...   \n",
            "584     webNLG  Afonso_Pena_International_Airport | cityServed...   \n",
            "...        ...                                                ...   \n",
            "1638    webNLG  Abilene_Regional_Airport | cityServed | Abilen...   \n",
            "1095    webNLG  Adolfo_Suárez_Madrid–Barajas_Airport | runwayL...   \n",
            "1130    webNLG  Afonso_Pena_International_Airport | location |...   \n",
            "1294    webNLG  Amsterdam_Airport_Schiphol | cityServed | Amst...   \n",
            "860     webNLG  Appleton_International_Airport | location | Gr...   \n",
            "\n",
            "                                            target_text  \n",
            "1280  Alpena County Regional Airport is found in Map...  \n",
            "29    546m above sea level, the length of the 1st ru...  \n",
            "210   Allama Iqbal International Airport is located ...  \n",
            "1730  Agra Airport is located in Uttar Pradesh which...  \n",
            "584   Afonso Pena International Airport serves the c...  \n",
            "...                                                 ...  \n",
            "1638  Abilene Regional Airport serves the city of Ab...  \n",
            "1095  Found in Madrid, Paracuellos de Jarama, San Se...  \n",
            "1130  The location of Afonso Pena International airp...  \n",
            "1294  Serving the city of Amsterdam, Amsterdam airpo...  \n",
            "860   Greenville is part of Grand Chute and Ellingto...  \n",
            "\n",
            "[2092 rows x 3 columns]\n",
            "---------------\n",
            "    challenge                                         input_text  \\\n",
            "190    webNLG  ENAIRE | city | Madrid && Madrid | country | S...   \n",
            "184    webNLG  Ashgabat_International_Airport | operatingOrga...   \n",
            "30     webNLG  Amsterdam_Airport_Schiphol | elevationAboveThe...   \n",
            "13     webNLG  Al_Asad_Airbase | elevationAboveTheSeaLevelInF...   \n",
            "250    webNLG  Belgium | leader | Philippe_of_Belgium && Antw...   \n",
            "..        ...                                                ...   \n",
            "241    webNLG  Ashgabat_International_Airport | location | As...   \n",
            "193    webNLG  Egg_Harbor_Township,_New_Jersey | isPartOf | N...   \n",
            "219    webNLG  Alpena_County_Regional_Airport | location | Wi...   \n",
            "189    webNLG  ENAIRE | city | Madrid && Madrid | country | S...   \n",
            "89     webNLG  Andrews_County_Airport | location | Texas && A...   \n",
            "\n",
            "                                           target_text  \n",
            "190  ENAIRE is located in Madrid, which, in turn, i...  \n",
            "184  Turkmenistan airlines are the operating organi...  \n",
            "30   Schiphol Group operates the Amsterdam Airport ...  \n",
            "13   The Al Asad Airbase, which is 618 ft above sea...  \n",
            "250  Antwerp, Belgium, is led by Philippe of Belgiu...  \n",
            "..                                                 ...  \n",
            "241  Ashgabat International Airport (located in Ash...  \n",
            "193  Egg Harbor Township, New Jersey is part of New...  \n",
            "219  Alpena County Regional Airport is located in t...  \n",
            "189  Operated by ENAIRE (Madrid, Spain), the Adolfo...  \n",
            "89   Andrews County Airport in Texas has a runway l...  \n",
            "\n",
            "[253 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"t5-base\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)\n",
        "#moving the model to device(GPU/CPU)\n",
        "model.to(dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mGuAKgwH9mb",
        "outputId": "2b04b357-e1d7-471e-f9a1-dfccc54a0c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"WebNLG: \"\n",
        "\n",
        "def preprocess_function(df):\n",
        "  # inputs, targets = [], []\n",
        "  model_inputs = []\n",
        "  for indx,row in df.iterrows():\n",
        "    inputs = prefix + row[\"input_text\"] + '</s>'\n",
        "    targets = row['target_text']+'</s>'\n",
        "    model_inputs.append(tokenizer(inputs, text_target=targets, max_length=400, truncation=True))\n",
        "  return model_inputs\n",
        "\n",
        "# Application du pre-processing à l'ensemble du dataset\n",
        "train_tok = preprocess_function(train_df)\n",
        "dev_tok = preprocess_function(dev_df)"
      ],
      "metadata": {
        "id": "Nlhm28d2IEpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By changing to False, the trainer will use the existing `model` and continue the training\n",
        "# Setting to `True` reloads a fresh t5-base model\n",
        "\n",
        "train_from_scratch = True\n",
        "\n",
        "if train_from_scratch:\n",
        "  model = T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)\n",
        "  model.to(dev)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name, max_length=400)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"t5-webnlg\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=8,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    load_best_model_at_end=True,\n",
        "    generation_max_length=128,\n",
        "    # predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=dev_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "hAzCWYy9IIdy",
        "outputId": "9e087c63-da07-48b5-e88c-639fcf483f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 3598 has 14.73 GiB memory in use. Of the allocated memory 14.04 GiB is allocated by PyTorch, and 573.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-e4849b7686b7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_from_scratch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorForSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m                 )\n\u001b[0;32m-> 3157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 3598 has 14.73 GiB memory in use. Of the allocated memory 14.04 GiB is allocated by PyTorch, and 573.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "VV2XKt7GIQtJ",
        "outputId": "22fc90a8-365b-46d8-8777-8c9e67090284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 3598 has 14.73 GiB memory in use. Of the allocated memory 14.04 GiB is allocated by PyTorch, and 573.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2123\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2124\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2479\u001b[0m                     )\n\u001b[1;32m   2480\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3578\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3579\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3581\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             \u001b[0;31m# move labels to correct device to enable PP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1928\u001b[0m             \u001b[0;31m# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3480\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 3598 has 14.73 GiB memory in use. Of the allocated memory 14.04 GiB is allocated by PyTorch, and 573.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning_rate : Contrôle l'ampleur des ajustements des poids du modèle pendant l'entraînement. Une valeur plus faible entraîne un apprentissage plus lent, mais potentiellement plus stable.\n",
        "per_device_train_batch_size : Le nombre d'exemples d'entraînement traités simultanément. Des lots plus importants peuvent accélérer l'entraînement, mais nécessitent plus de mémoire.\n",
        "per_device_eval_batch_size : Similaire à la taille du lot d'entraînement, mais pour l'évaluation. Une taille de lot plus importante peut accélérer l'évaluation."
      ],
      "metadata": {
        "id": "NdwnzOi4Jp80"
      }
    }
  ]
}